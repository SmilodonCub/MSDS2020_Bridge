---
title: "A Prussian Poisson Process"
author: "Bonnie Cooper"
date: "1/12/2019"
output: html_document 
---

![Prussian Calvary on Parade](https://i.imgur.com/N9ZAWAO.png)

<font size="2"> Image source: [picclick](https://picclick.com/Antique-Print-Vintage-1851-Engraving-Military-History-British-233240629258.html) </font>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
### Demonstrating a Poisson distribution with a classic data set: the von Bortkeiwicz Prussian horse-kicking data


The Poisson process is a useful model applied to occurances where, while individual events occur randomly, thier regularity can be described by a consistent rate. In this R notebook, we will discuss Poisson processes and give a thorough demonstration of the Poisson distribution using a classic data set, the von Bortkeisicz Prussian horse-kicking data. The commented R code bellow will give a step-by-step exploration and visualization of the data. Our goal will be to evaluate the goodness of fit of the Poisson distribution to the horse-kicking data.
But first, a brief introduction to the data, Poisson processes, and the Poisson distribution.

*** 
### Introduction

### von Bortkiewicz & the Law of Small Numbers

Ladislaus Josephovich Bortkiewicz (9/1868 – 8/1931) was a Russian born man of Polish descent who established his career as an economist and statistician in Germany. In 1898, he published his first book, 'Das Gesetz der kleinen Zahlen', or, 'The Law of Small Numbers'. This Monograph introduces the Law of Small Numbers and in the process gave a detailed discussion of the Poisson distribution using real-world data sets such as the Prussian horse-kicking data. In short, the Law of Small Numbers states that when there are small numbers of events out of a comparatively many observations, that the observations trend towards a mean value. While the interpretation and even the name of the Law was met with criticism (Sheynin, 2008), the applied statistics to real world examples of Poisson processes has made for an enduring legacy for 'Das Gesetz der kleinen Zahlen'. In this Demo, we will be using the same Prussian horse-kicking data set used by von Bortkiewicz for our analysis as made available by the [Visualizing Categorical Data (vcd)](https://cran.r-project.org/web/packages/vcd/index.html) package for R.


### Poisson Process & the Poisson Distribution (a cursory overview)
The Bortkiewicz horse-kicking data was collected over a 20 year period (1875-1984) from 14 different calvalry corps. It gives number of soldiers that died by horse kick for each division. The horse-kicking data exemplifies a classic Poisson process: observations of rare and independent events distributed over many observation intervals with a resultant low average rate of occurance. While the Poisson process had previously been described, von Bortkiewicz was the first to depict the Poisson distribution with his data. The Poisson distribution is a plot of the proportion or probability of events as a function of the number of events for a given time interval. the Poisson distribution has only one parameter, the mean, and it makes the assumption that the events are random and discrete. That is to say, that the occurance of one event is not predicated or otherwise effected by the previous event(s). The von Bortkiewicz data satifies the assumptons of a Poisson process, because death by horse-kicking is a rare and random event and a horse-kicking event in one corps is not reliant on the next occurance in that or any other corps. The Poisson distribution of the horse-kicking data describes the probability of the number of horse-kicking deaths for given corps for a year. 

The following R notebook will introduce us to the von Bortkiewicz data set and build the Poisson distribution.

 

![Ladislaus Josephovich Bortkiewicz and the cover of his book, 'Das Gesetz der kleinen Zahlen', or, 'The Law of Small Numbers'](https://i.imgur.com/Yb5tfBn.png)

<font size="2"> Image source: [wikipedia](https://en.wikipedia.org/wiki/Ladislaus_Bortkiewicz) and [AbeBooks](https://www.abebooks.com/9781287795223/Gesetz-kleinen-Zahlen-German-Edition-1287795226/plp)</font>

***
### Horse-kicking Data Exploration


Set up the right environment by loading several relevant libraries
```{r,warning=FALSE,message=FALSE}
library(dplyr)
library(magrittr)
library(knitr)
library(RCurl)
```

For this demo, the VonBort dataset was selected from the [Visualizing Categorical Data](https://cran.r-project.org/web/packages/vcd/index.html) (vcd) library as listed on [Rdatasets](http://vincentarelbundock.github.io/Rdatasets/)
For the convenience of this demo, the Von Bortkiewicz Horsekick Dataset, 'VonBort.csv' from the vcd package has been placed in a github file. This code will read the .csv from the link as a data.frame.
```{r}

myURL <- 'https://raw.githubusercontent.com/SmilodonCub/MSDS2020_Bridge/master/VonBort.csv' 
gitVonBort <- read.csv( url( myURL ) ) # read.csv is a built in function that will read the csv data as an R dataframe.
#head( gitVonBort ) # head() will by default display the first 6 rows of the dataframe
head( gitVonBort, 4 ) # the second argument customizes the number of lines made visible
```

## Data Exploration

To start, let's get an idea of the basic size and complexity of the data set.

```{r pressure, echo=FALSE}
vbrows <- nrow( gitVonBort )
vbcols <- ncol( gitVonBort )
paste0("Num data entries in VonBort dataset: ", vbrows)
paste0("Num features in VonBort dataset: ", vbcols)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
```{r}
vonbortC <- gitVonBort
agg_bycorps <- vonbortC %>%
  group_by(corps) %>%
  summarise(Total = sum(deaths),
            Mean = mean(deaths))
agg_bycorps <- agg_bycorps[order(agg_bycorps$Total, decreasing = TRUE),]  
mostdeaths_corps <- agg_bycorps[1,]
mostdeaths_corps[1,]
```
,.,.,
vh,bjm
```{r}
agg_byyear <- vonbortC %>%
  group_by(year) %>%
  summarise(Total = sum(deaths),
            Mean = mean(deaths))
agg_byyear <- agg_byyear[order(agg_byyear$Total, decreasing = TRUE),]
mostdeaths_year <- agg_byyear[ 1, ]
mostdeaths_year
```
gjhkbh,n
```{r}
library(dplyr)
#aggby_yearcorps <- vonbortC %>% group_by(year, corps) %>% summarise_each(funs(sum))
aggby_yearcorps <- aggregate(cbind(deaths) ~ year + corps, data = vonbortC, sum, na.rm = TRUE)
max_aggby_yearcorps <- aggregate(deaths ~ year, aggby_yearcorps, max)
#max_aggby_yearcorps
max_byyear <- merge(max_aggby_yearcorps, aggby_yearcorps)
#max_byyear
maxlist_byyear <- max_byyear %>% 
         group_by(year, deaths) %>%
         summarise(corps = toString(unique(corps)))
maxlist_byyear
```

```{r}
#data("VonBort")
## HorseKicks data
xtabs(~ deaths, data = gitVonBort, subset = fisher == "yes")

#Data from von Bortkiewicz (1898), given by Andrews \& Herzberg (1985), on number of deaths by horse or mule kicks in 10 (of 14 reported) corps of the Prussian army. 4 corps were not considered by Fisher (1925) as they had a different organization. This data set is a popular subset of the VonBort data.
#data("HorseKicks")
#gf <- goodfit(HorseKicks)
#summary(gf)
#plot(gf)
```

```{r}
#will start by writing the data
#write.csv( VonBort, file ='VonBort.csv', row.names = FALSE)
#Great! I see it in my directory, so now i'll beam it up to git.....
#......
#That worked, what a time to be alive.



#Bortkiewicz researched the annual deaths by horse kicks in the Prussian Army from 1875-1984. Data was recorded from 14 different army corps, with one being the Guard Corps. (According to one Wikipedia article on the subject, the Guard Corps may have been responsible for Prussia’s elite Guard units.)

```
#### References
The Poisson Distribution and Poisson Process Explained
Will Koehrsen - https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459
Quine, M. P., and E. Seneta. "Bortkiewicz's data and the law of small numbers." International Statistical Review/Revue Internationale de Statistique (1987): 173-181.
Sheynin, Oscar. "Bortkiewicz’Alleged Discovery: the Law of Small Numbers." Historiasci-entiarum, Second series: International Journal of the History of Science Society of Japan 18.1 (2008): 36-48.



## R Bridge Course Final Project


The presentation approach is up to you, but it should contain the following:  
1. Data Exploration: This should include summary statistics, means, medians, quartiles, or any
other relevant information about the data set. Please include some conclusions in the R
Markdown text.  
2. Data wrangling: Please perform some basic transformations. They will need to make sense but
could include column renaming, creating a subset of the data, replacing values, or creating new
columns with derived data (for example – if it makes sense you could sum two columns
together)  
3. Graphics: Please make sure to display at least one scatter plot, box plot and histogram. Don’t
be limited to this. Please explore the many other options in R packages such as ggplot2.  
4. Meaningful question for analysis: Please state at the beginning a meaningful question for
analysis. Use the first three steps and anything else that would be helpful to answer the
question you are posing from the data set you chose. Please write a brief conclusion paragraph
in R markdown at the end.  
